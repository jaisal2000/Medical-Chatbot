{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007100eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Jaisal\\\\OneDrive\\\\Desktop\\\\New_me\\\\Langchain_Projects\\\\Medical-Chatbot\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd0dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "553e238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Jaisal\\\\OneDrive\\\\Desktop\\\\New_me\\\\Langchain_Projects\\\\Medical-Chatbot'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ebd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252d40d",
   "metadata": {},
   "source": [
    "## Extract the data from the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                              glob=\"*.pdf\",\n",
    "                              loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e21b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data = 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c2e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the documents into smaller chunks\n",
    "\n",
    "def text_splitter(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f203bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 5699\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_splitter(extracted_data)\n",
    "print(f\"Total number of chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8957d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the embeddings from Hugging Face\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd0de7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af5396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaisal\\AppData\\Local\\Temp\\ipykernel_21604\\3649822238.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b433b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the query: 384\n"
     ]
    }
   ],
   "source": [
    "query = embeddings.embed_query(\"What is the capital of France?\")\n",
    "print(f\"length of the query: {len(query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d44e9e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c454379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc168f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-db\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6730c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"medical-db\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38867ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "'''\n",
    "# Already loaded the data into Pinecone, uncomment the above code to load the data into Pinecone if you are running this notebook for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1383fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the existing index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3afbcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "283ba866",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is types of diabeties?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62739494",
   "metadata": {},
   "source": [
    "## Checking whether our query can be answered by retrieving\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d7684fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5688ae4a-8f0b-4116-bfd5-ca59fba4f1ea', metadata={'author': 'Clifford', 'creationdate': '2004-12-28T15:38:25-05:00', 'creator': 'PyPDF', 'enhanced': 'By PDF Enhancer 2.5/Win', 'moddate': '2005-05-04T13:53:15-06:00', 'page': 47.0, 'page_label': '48', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Med_book.pdf', 'spdf': '1096', 'total_pages': 599.0}, page_content='stop responding to the insulin that is produced, so that\\nglucose in the blood cannot be absorbed into the cells of\\nthe body . Symptoms include frequent urination, tired-\\nness, excessive thirst, and hunger.\\nDescription\\nDiabetes mellitus is a chronic disease that causes se-\\nrious health complications including renal (kidney) fail-\\nure, heart disease , stroke, and blindness. Approximate-\\nly 14 million Americans (about 5% of the population)\\nhave diabetes. Unfortunately , as many as one-half of'),\n",
       " Document(id='19d3abbd-0251-400e-b340-60b7b242e82d', metadata={'author': 'Clifford', 'creationdate': '2004-12-28T15:38:25-05:00', 'creator': 'PyPDF', 'enhanced': 'By PDF Enhancer 2.5/Win', 'moddate': '2005-05-04T13:53:15-06:00', 'page': 47.0, 'page_label': '48', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Med_book.pdf', 'spdf': '1096', 'total_pages': 599.0}, page_content='stop responding to the insulin that is produced, so that\\nglucose in the blood cannot be absorbed into the cells of\\nthe body . Symptoms include frequent urination, tired-\\nness, excessive thirst, and hunger.\\nDescription\\nDiabetes mellitus is a chronic disease that causes se-\\nrious health complications including renal (kidney) fail-\\nure, heart disease , stroke, and blindness. Approximate-\\nly 14 million Americans (about 5% of the population)\\nhave diabetes. Unfortunately , as many as one-half of'),\n",
       " Document(id='ab18041b-5f36-42d1-afb6-cde8048a8598', metadata={'author': 'Clifford', 'creationdate': '2004-12-28T15:38:25-05:00', 'creator': 'PyPDF', 'enhanced': 'By PDF Enhancer 2.5/Win', 'moddate': '2005-05-04T13:53:15-06:00', 'page': 395.0, 'page_label': '396', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Med_book.pdf', 'spdf': '1096', 'total_pages': 599.0}, page_content='intestines.\\nDiabetes —A group of metabolic disorders in\\nwhich the body produces insufficient insulin or is\\nresistant to the insulin it does produce, causing\\nglucose levels to rise in the blood.\\nFasting—Avoiding food for a period of time.\\nFibrinogen —A protein that is important in blood\\nclotting.\\nHomocysteine—An amino acid derived from pro-\\ntein in food that can build up in the blood and\\ncontribute to the development of heart disease.\\nLipids —Organic compounds that are greasy , in-')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cef2b",
   "metadata": {},
   "source": [
    "The answer is retrieved, but we need to make it more readable form for the user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3f84c9",
   "metadata": {},
   "source": [
    "## Initializing the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3550ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f2c99",
   "metadata": {},
   "source": [
    "### Flan T5 Base as LLM\n",
    "\n",
    "Since, I am running this code in my low end laptop with only CPU, I preferred a smaller model for the LLM task. You can freely replace this with larger models or even the premium ones like OpenAI GPTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bfb583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaisal\\anaconda3\\envs\\medbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Jaisal\\anaconda3\\envs\\medbot\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jaisal\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "C:\\Users\\Jaisal\\AppData\\Local\\Temp\\ipykernel_21604\\4105082708.py:21: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "model_id = \"google/flan-t5-base\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "# Create Hugging Face pipeline\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    device_map=\"auto\"  # Uses GPU if available, else CPU\n",
    ")\n",
    "\n",
    "# Wrap the pipeline with LangChain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b5716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a helpful assistant that provides information about diabetes. \"\n",
    "    \"You will be provided with some context and you need to answer the question based on the context.Use three sentences maximum and keep the answer short. \"\n",
    "    \"If the context does not contain the answer, say 'I don't know'. \"\n",
    "    \"If the context is too long, summarize it in three sentences maximum. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8e8a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_docs_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb435bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A group of metabolic disorders in which the body produces insufficient insulin or is resistant to the insulin it does produce, causing glucose levels to rise in the blood.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is diabetes?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77feab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
